{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this project, we'll be predicting the number of upvotes the articles received, based on their title. Because upvotes are an indicator of popularity, we'll discover which types of articles tend to be the most popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client_id = 'c6aloydyNEh81A'\n",
    "secret = 'A6kOhLnbyLUI-zUU4i19pOZLTYg'\n",
    "\n",
    "#-----------------Import Modules-----------------#\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-----------------Define variables-----------------#\n",
    "subreddit = 'python'\n",
    "data_list = {}\n",
    "rows = 10000\n",
    "\n",
    "\n",
    "#-----------------connect to reddit api using Praw wrapper-----------------#\n",
    "reddit = praw.Reddit(client_id= client_id, client_secret = secret, username = '',\n",
    "                     password  ='PuzzledTarget', user_agent ='Incubator_project')\n",
    "\n",
    "#-----------------extract data from the subreddit -----------------#\n",
    "subreddit = reddit.subreddit(subreddit)\n",
    "\n",
    "# extracting from the hot tab ( Time and votes are considered for hot rating)\n",
    "hot_python = subreddit.hot(limit = rows)\n",
    "\n",
    "\n",
    "for submission in hot_python:\n",
    "    if not submission.stickied:\n",
    "        if submission.id not in data_list :\n",
    "            created_time = (datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            data_list[submission.id] =[submission.title, submission.ups, submission.downs, created_time, submission.upvote_ratio]\n",
    "        else:\n",
    "            raise ValueError('duplicate id found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>create_time</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cix5ek</th>\n",
       "      <td>I made a script that uses the mouse and keyboa...</td>\n",
       "      <td>1466</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-28 15:28:37</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cj143q</th>\n",
       "      <td>Robot with live feed built using pynetwork</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-28 20:41:37</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>civysm</th>\n",
       "      <td>I'm trying to make a flappy bird replica in py...</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-28 13:43:52</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cj9he8</th>\n",
       "      <td>An interview covering what you need to know ab...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-29 10:33:45</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cj958g</th>\n",
       "      <td>Building a PEG Parser</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-29 09:56:51</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title   ups  downs  \\\n",
       "cix5ek  I made a script that uses the mouse and keyboa...  1466      0   \n",
       "cj143q         Robot with live feed built using pynetwork   102      0   \n",
       "civysm  I'm trying to make a flappy bird replica in py...   336      0   \n",
       "cj9he8  An interview covering what you need to know ab...     4      0   \n",
       "cj958g                              Building a PEG Parser     3      0   \n",
       "\n",
       "                create_time  upvote_ratio  \n",
       "cix5ek  2019-07-28 15:28:37          0.98  \n",
       "cj143q  2019-07-28 20:41:37          0.96  \n",
       "civysm  2019-07-28 13:43:52          0.93  \n",
       "cj9he8  2019-07-29 10:33:45          1.00  \n",
       "cj958g  2019-07-29 09:56:51          1.00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-----------------Create a pandas DataFrame out of the dictionary -----------------#\n",
    "columns = ['title' , 'ups' , 'downs', 'create_time' , 'upvote_ratio' ]\n",
    "reddit_submission = pd.DataFrame.from_dict(data_list, orient = 'index' , columns = columns)\n",
    "reddit_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let explore the dataset \n",
    "reddit_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------null rows --------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are no nulls in the dataset\n",
    "print(20*'-' + 'null rows '+ 20*'-')\n",
    "reddit_submission[reddit_submission.isnull().any(axis=1)]\n",
    "\n",
    "# let is look at the  ups colums \n",
    "print(20*'-' + 'ups distribution '+ 20*'-')\n",
    "reddit_submission['ups'].value_counts()\n",
    "#365 elements out 910 have 0 votes\n",
    "\n",
    "# let is look at the upvote_ratio colums  - There is atleast one upvote\n",
    "print(20*'-' + 'upvote_ratio '+ 20*'-')\n",
    "reddit_submission['upvote_ratio'].value_counts().sort_index().head()\n",
    "\n",
    "\n",
    "# let is look at the time ups colums  - There is atleast one upvote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# covert each title into a numerical repesentation\n",
    "tokenized_title = []\n",
    "\n",
    "for item in reddit_submission['title']:\n",
    "    tokenized_title.append(item.split(\" \"))\n",
    "    \n",
    "# lowercase all the items and removing punctuations\n",
    "punctuation = [\",\", \":\", \";\", \".\", \"'\", '\"', \"â€™\", \"?\", \"/\", \"-\", \"+\", \"&\", \"(\", \")\", \"|\" , \">\" , \"<\" , \"[\" , \"]\" , \"-\"]\n",
    "\n",
    "clean_tokenized = []\n",
    "\n",
    "for item in tokenized_title:\n",
    "    tokens = []\n",
    "    for token in item:\n",
    "        token = token.lower()\n",
    "        for punc in punctuation:\n",
    "            token = token.replace(punc, \"\")\n",
    "        if token != \"\":\n",
    "            tokens.append(token)\n",
    "    clean_tokenized.append(tokens)\n",
    "clean_tokenized\n",
    "\n",
    "# find all the unique token in clean_tokenised and assign the result to unique tokenize. Any token occuring\n",
    "#only 1 time will not be counted as \n",
    "\n",
    "unique_tokens = []\n",
    "single_token =[]\n",
    "\n",
    "for item in clean_tokenized:\n",
    "    for element in item:\n",
    "        if element not in  single_token:\n",
    "            single_token.append(element)\n",
    "        elif element in single_token and element not in unique_tokens:\n",
    "            unique_tokens.append(element)\n",
    "\n",
    "len(unique_tokens)\n",
    "\n",
    "\n",
    "# initialising DataFrame to hold the numeric values for each token \n",
    "counts =  pd.DataFrame(0, index = np.arange(len(clean_tokenized)) , columns = unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,item in enumerate(clean_tokenized):\n",
    "    for element in item:\n",
    "        if element in unique_tokens:\n",
    "            counts.iloc[i][element] +=1 \n",
    "        else:\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "that       50\n",
       "it         49\n",
       "an         44\n",
       "code       43\n",
       "can        41\n",
       "what       39\n",
       "you        38\n",
       "data       38\n",
       "made       33\n",
       "or         31\n",
       "web        30\n",
       "script     30\n",
       "project    30\n",
       "any        29\n",
       "need       28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = counts.sum(axis =0)\n",
    "word_counts.sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features or words occuring too few times will result in overfillting These feature will probably correlates differently with upvote in training set and testing set.Features or words occuring too many times will also cause issue (stopwords - such as 'and','or' etc). They do not add any information to the model. \n",
    "\n",
    "After having a look at the word_count distribution, to make the model better we reduce the feature by removing words that occur less than 5 times or more than 50 times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 249)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = counts.loc[:,(word_counts >=5) & (word_counts <=50)]\n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will split the data into 2 sets. Test and train to evaluate the algorithm effectively. we will select 20% of our rows for test and 80% of our rows for training. We will use linear regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(counts, reddit_submission[\"ups\"], test_size=0.2, random_state=1)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets us calculate the MSE (mean square error associated with our predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202.81453211430687"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((predictions - y_test)**2).sum()/len(predictions)\n",
    "mse**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.785714285714285"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_submission[\"ups\"].describe()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the dataset size of 986 rows - \n",
    "the mean for our up_votes is 33 and the std deviation is 170. if we take the square root of out mse, we get 182.5.This means that the average error is 182  upvotes away from the true value. This is highter than the standard deviation, so out predictions are far off the base.\n",
    "Let us go ahead and increase the size of the data used\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, reddit_submission[\"ups\"], test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "train_rows = int(counts.shape[0]* .8)\n",
    "# Set a seed to get the same \"random\" shuffle every time.\n",
    "random.seed(1)\n",
    "\n",
    "# Shuffle the indices for the matrix.\n",
    "indices = list(range(counts.shape[0]))\n",
    "random.shuffle(indices)\n",
    "\n",
    "\n",
    "# Create train and test sets.\n",
    "X_train_ridge = counts.loc[indices[:train_rows], :]\n",
    "X_test_ridge = counts.loc[indices[train_rows:], :]\n",
    "y_train_ridge = reddit_submission[\"ups\"].iloc[indices[:train_rows]]\n",
    "y_test_ridge = reddit_submission[\"ups\"].iloc[indices[train_rows:]]\n",
    "X_train_ridge = numpy.nan_to_num(X_train_ridge)\n",
    "\n",
    "# Run the regression and generate predictions for the test set.\n",
    "reg = Ridge(alpha=.1)\n",
    "reg.fit(X_train_ridge, y_train_ridge)\n",
    "predictions_ridge = reg.predict(X_test_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196.16180979416899"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((predictions - test_upvotes)**2).sum()/len(test_upvotes)\n",
    "mse**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174.72759000451327"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_submission[\"ups\"].describe()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(data = predictions , index = test.index )\n",
    "reddit_submission.index = counts.index\n",
    "reddit_submission.loc[test.index,:]\n",
    "reddit_predictions = pd.merge(reddit_submission, predictions, left_index = True, right_index = True)\n",
    "reddit_predictions = reddit_predictions.reindex()\n",
    "reddit_predictions['predicted_ups'] = reddit_predictions[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-c04725b65cf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# top 5 posts that have maximum predicted up_votes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreddit_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted_ups'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# top 5 posts that have maximum predicted up_votes\n",
    "# top 5 posts that have maximum predicted up_votes\n",
    "top = {}\n",
    "top['python'] = np.array[reddit_predictions.sort_values('predicted_ups' , ascending = False)['title'].head()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563    Greetings Python enthusiasts of reddit, I seek...\n",
       "906    I made a program which encrypts the RGB value ...\n",
       "712    I wrote a tiny Python API that notifies you if...\n",
       "662    I made a small Python program to automatically...\n",
       "824    I made a toy renderer to work on shaders. PyOp...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_predictions.sort_values('predicted_ups' , ascending = False)['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_ups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>Greetings Python enthusiasts of reddit, I seek...</td>\n",
       "      <td>814.157433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>I made a program which encrypts the RGB value ...</td>\n",
       "      <td>804.525155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>I wrote a tiny Python API that notifies you if...</td>\n",
       "      <td>532.764095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>I made a small Python program to automatically...</td>\n",
       "      <td>512.430284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>I made a toy renderer to work on shaders. PyOp...</td>\n",
       "      <td>486.349808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  predicted_ups\n",
       "563  Greetings Python enthusiasts of reddit, I seek...     814.157433\n",
       "906  I made a program which encrypts the RGB value ...     804.525155\n",
       "712  I wrote a tiny Python API that notifies you if...     532.764095\n",
       "662  I made a small Python program to automatically...     512.430284\n",
       "824  I made a toy renderer to work on shaders. PyOp...     486.349808"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = reddit_predictions.sort_values('predicted_ups' , ascending = False)[['title', 'predicted_ups']].head()\n",
    "\n",
    "top = top.reindex()\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-0f31a58d68ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreddit_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predicted_ups'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "reddit_predictions[['title', 'predicted_ups']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'reindex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-64d3c36f28c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreddit_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreddit_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'reindex'"
     ]
    }
   ],
   "source": [
    "reddit_predictions = reddit_predictions.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
